{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('anna.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "vocab = set(text)\n",
    "vocab2int = {c:i for i,c in enumerate(vocab)}\n",
    "int2vocab = dict(enumerate(vocab))\n",
    "encoded = np.array([vocab2int[c] for c in text], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chapter 1\\n\\n\\nHappy families are all alike; every unhappy family is unhappy in its own\\nway.\\n\\nEverythin'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([47, 64, 65, 80, 45, 46, 36, 73, 20, 72, 72, 72, 75, 65, 80, 80, 78,\n",
       "       73, 56, 65, 69, 81, 19, 81, 46, 41, 73, 65, 36, 46, 73, 65, 19, 19,\n",
       "       73, 65, 19, 81, 55, 46, 58, 73, 46, 34, 46, 36, 78, 73, 70, 14, 64,\n",
       "       65, 80, 80, 78, 73, 56, 65, 69, 81, 19, 78, 73, 81, 41, 73, 70, 14,\n",
       "       64, 65, 80, 80, 78, 73, 81, 14, 73, 81, 45, 41, 73, 11, 74, 14, 72,\n",
       "       74, 65, 78,  2, 72, 72,  3, 34, 46, 36, 78, 45, 64, 81, 14], dtype=int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_batches(arr, n_seqs, num_steps):\n",
    "    '''Create a generator that returns batches of size\n",
    "       n_seqs x n_steps from arr.\n",
    "       \n",
    "       Arguments\n",
    "       ---------\n",
    "       arr: Array you want to make batches from\n",
    "       n_seqs: Batch size, the number of sequences per batch\n",
    "       n_steps: Number of sequence length(steps) per batch\n",
    "    '''\n",
    "    # Get the batch size and number of batches we can make\n",
    "    batch_size = n_seqs*num_steps\n",
    "    n_batches = len(arr)//batch_size\n",
    "    \n",
    "    # Keep only enough characters to make full batches\n",
    "    arr = arr[:batch_size*n_batches]\n",
    "    \n",
    "    # Reshape into n_seqs rows\n",
    "    arr = np.reshape(arr, [n_seqs,n_batches*num_steps])\n",
    "    \n",
    "    for n in range(0, arr.shape[1], num_steps):\n",
    "        # The features\n",
    "        x = arr[:n_seqs, 0+n*num_steps:num_steps+n*num_steps]\n",
    "        # The targets, shifted by one\n",
    "        y = np.zeros_like(x)\n",
    "        y[:,:-1], y[:,-1] = x[:,1:], x[:,0]\n",
    "        yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = get_batches(encoded, 10, 50)\n",
    "x, y = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\n",
      " [[47 64 65 80 45 46 36 73 20 72]\n",
      " [73 65 69 73 14 11 45 73 26 11]\n",
      " [34 81 14  2 72 72 22 12 46 41]\n",
      " [14 73 21 70 36 81 14 26 73 64]\n",
      " [73 81 45 73 81 41 43 73 41 81]\n",
      " [73 44 45 73 74 65 41 72 11 14]\n",
      " [64 46 14 73  7 11 69 46 73 56]\n",
      " [58 73  8 70 45 73 14 11 74 73]\n",
      " [45 73 81 41 14 42 45  2 73 57]\n",
      " [73 41 65 81 21 73 45 11 73 64]]\n",
      "\n",
      "y\n",
      " [[64 65 80 45 46 36 73 20 72 72]\n",
      " [65 69 73 14 11 45 73 26 11 81]\n",
      " [81 14  2 72 72 22 12 46 41 43]\n",
      " [73 21 70 36 81 14 26 73 64 81]\n",
      " [81 45 73 81 41 43 73 41 81 36]\n",
      " [44 45 73 74 65 41 72 11 14 19]\n",
      " [46 14 73  7 11 69 46 73 56 11]\n",
      " [73  8 70 45 73 14 11 74 73 41]\n",
      " [73 81 41 14 42 45  2 73 57 64]\n",
      " [41 65 81 21 73 45 11 73 64 46]]\n"
     ]
    }
   ],
   "source": [
    "print('x\\n', x[:10, :10])\n",
    "print('\\ny\\n', y[:10, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the model\n",
    "<br>\n",
    "# RNN Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_inputs(batch_size, num_steps):\n",
    "    ''' Define placeholders for inputs, targets, and dropout \n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        batch_size: Batch size, number of sequences per batch\n",
    "        num_steps: Number of sequence steps in a batch\n",
    "        \n",
    "    '''\n",
    "    # Declare placeholders we'll feed into the graph\n",
    "    inputs = tf.placeholder(tf.int32, shape=(batch_size,num_steps), name='inputs')\n",
    "    targets = tf.placeholder(tf.int32, shape=(batch_size,num_steps), name='targets')\n",
    "    \n",
    "    # Keep probability placeholder for drop out layers\n",
    "    keep_prob = tf.placeholder(tf.float32, name='keep_prob')\n",
    "    \n",
    "    return inputs, targets, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_lstm(lstm_size, num_layers, batch_size, keep_prob):\n",
    "    ''' Build LSTM cell.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        keep_prob: Scalar tensor (tf.placeholder) for the dropout keep probability\n",
    "        lstm_size: Size of the hidden layers in the LSTM cells\n",
    "        num_layers: Number of LSTM layers\n",
    "        batch_size: Batch size 用来生成initial_state, 此例中详见下图\n",
    "\n",
    "    '''\n",
    "    ### Build the LSTM Cell\n",
    "    # Use a basic LSTM cell\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    \n",
    "    # Add dropout to the cell outputs\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob = keep_prob)\n",
    "    \n",
    "    # Stack up multiple LSTM layers, for deep learning\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop for _ in range(num_layers)])\n",
    "    \n",
    "    # batch_size: 一个batch的总字符数\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32) \n",
    "    \n",
    "    return cell, initial_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_output(lstm_output, in_size, out_size):\n",
    "    ''' Build a softmax layer, return the softmax output and logits.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        \n",
    "        lstm_output: List of output tensors from the LSTM layer\n",
    "        # outputs: [batch_size, max_time(n_steps), hidden units(lstm_size)]\n",
    "        in_size: Size of the input tensor, for example, size of the LSTM cells \n",
    "        # lstm_size \n",
    "        out_size: Size of this softmax layer\n",
    "        # softmax layer应该和text中出现的字母种类数保持一致, num_classes\n",
    "    '''\n",
    "\n",
    "    # Reshape output so it's a bunch of rows, one row for each step for each sequence.\n",
    "    # Concatenate lstm_output over axis 1 (the columns)\n",
    "    print('\\n lstm_output ==>\\n',lstm_output)\n",
    "    seq_output = tf.concat(lstm_output, axis=1)\n",
    "    print('\\n seq_output ==>\\n',seq_output)\n",
    "    # Reshape seq_output to a 2D tensor with lstm_size columns\n",
    "    # reshape中的-1表示推断, 即给出其中一个维度参数的情况下, 推断出另一个维度应该是多少\n",
    "    # in_size表示LSTM cell的个数, 这一步的输出应该是每层cell的输出列成一列\n",
    "    x = tf.reshape(seq_output, [-1,in_size]) \n",
    "    print('\\n seq_output.reshape\\n',x)\n",
    "    # Connect the RNN outputs to a softmax layer\n",
    "    with tf.variable_scope('softmax'):\n",
    "        # Create the weight and bias variables here\n",
    "        softmax_w = tf.Variable(tf.truncated_normal([in_size,out_size], stddev=0.1, dtype=tf.float32))\n",
    "        softmax_b = tf.Variable(tf.zeros(out_size))\n",
    "    \n",
    "    # Since output is a bunch of rows of RNN cell outputs, logits will be a bunch\n",
    "    # of rows of logit outputs, one for each step and sequence\n",
    "    logits = tf.matmul(x, softmax_w) + softmax_b\n",
    "    \n",
    "    # Use softmax to get the probabilities for predicted characters\n",
    "    out = tf.nn.softmax(logits, name='prediction')\n",
    "    \n",
    "    return out, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_loss(logits, targets, lstm_size, num_classes):\n",
    "    ''' Calculate the loss from the logits and the targets.\n",
    "    \n",
    "        Arguments\n",
    "        ---------\n",
    "        logits: Logits from final fully connected layer\n",
    "        targets: Targets for supervised learning\n",
    "        lstm_size: Number of LSTM hidden units\n",
    "        num_classes: Number of classes in targets\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    # One-hot encode targets and reshape to match logits, one row per sequence per step\n",
    "    y_one_hot = tf.one_hot(targets, num_classes)\n",
    "    print('\\ny_one_hot ==>\\n',y_one_hot)\n",
    "    y_reshaped = tf.reshape(y_one_hot, shape=(logits.shape))\n",
    "    print('\\ny_reshaped ==>\\n',y_reshaped)\n",
    "    # Softmax cross entropy loss\n",
    "    loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y_reshaped)\n",
    "    print('\\nloss\\n ==>',loss)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    print('\\nloss_mean\\n ==>',loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_optimizer(loss, learning_rate, grad_clip):\n",
    "    ''' Build optmizer for training, using gradient clipping.\n",
    "    \n",
    "        Arguments:\n",
    "        loss: Network loss\n",
    "        learning_rate: Learning rate for optimizer\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # Optimizer for training, using gradient clipping to control exploding gradients\n",
    "    \n",
    "    # 只要Variable变量的 trainable = True(默认为True), 则tf.trainable_variables()会收集所有Variable类的实例(变量).\n",
    "    tvars = tf.trainable_variables()\n",
    "#     print('\\ntf.gradients(loss, tvars)\\n',tf.gradients(loss, tvars))\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(loss, tvars), grad_clip)\n",
    "#     print('\\ngrads\\n',grads)\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate)\n",
    "#     print('\\ntrain_op\\n',train_op)\n",
    "    optimizer = train_op.apply_gradients(zip(grads, tvars))\n",
    "    \n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CharRNN:\n",
    "    \n",
    "    def __init__(self, num_classes, batch_size=64, num_steps=50, \n",
    "                       lstm_size=128, num_layers=2, learning_rate=0.001, \n",
    "                       grad_clip=5, sampling=False):\n",
    "    \n",
    "        # When we're using this network for sampling later, we'll be passing in\n",
    "        # one character at a time, so providing an option for that\n",
    "        if sampling == True:\n",
    "            batch_size, num_steps = 1, 1\n",
    "        else:\n",
    "            batch_size, num_steps = batch_size, num_steps\n",
    "            \n",
    "        # Reset graph    \n",
    "        tf.reset_default_graph()\n",
    "        \n",
    "        #build input placeholder\n",
    "        self.inputs, self.targets, self.keep_prob = build_inputs(batch_size, num_steps) \n",
    "        \n",
    "        # Build the LSTM cell\n",
    "        self.lstm, self.initial_state = build_lstm(lstm_size, num_layers, batch_size, self.keep_prob)\n",
    "        \n",
    "        ### Run the data through the RNN layer\n",
    "        # one-hot encode the input token\n",
    "        x_one_hot = tf.one_hot(self.inputs, num_classes)\n",
    "        self.x_one_hot = x_one_hot\n",
    "        \n",
    "        # Run each sequence step through RNN with tf.nn.dynamic_run\n",
    "        outputs, state = tf.nn.dynamic_rnn(self.lstm, x_one_hot, initial_state=self.initial_state)\n",
    "        self.final_state = state\n",
    "        self.outputs = outputs\n",
    "        \n",
    "        # Get softmax prediction and logits\n",
    "        self.prediction, self.logits = build_output(outputs, lstm_size, num_classes)\n",
    "        \n",
    "        # Loss and optimizer (with gradient clipping)\n",
    "        self.loss =  build_loss(self.logits, self.targets, lstm_size, num_classes)\n",
    "        self.optimizer = build_optimizer(self.loss, learning_rate, grad_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "num_steps = 50\n",
    "lstm_size = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.01\n",
    "keep_prob = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " lstm_output ==>\n",
      " Tensor(\"rnn/transpose:0\", shape=(10, 50, 128), dtype=float32)\n",
      "\n",
      " seq_output ==>\n",
      " Tensor(\"concat:0\", shape=(10, 50, 128), dtype=float32)\n",
      "\n",
      " seq_output.reshape\n",
      " Tensor(\"Reshape:0\", shape=(500, 128), dtype=float32)\n",
      "y_one_hot ==> Tensor(\"one_hot_1:0\", shape=(10, 50, 83), dtype=float32)\n",
      "\n",
      "new_state ==>\n",
      " (LSTMStateTuple(c=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)), LSTMStateTuple(c=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32))) \n",
      "new_state.shape ==> \n",
      " 4 \n",
      "len ==> \n",
      " 2\n",
      "\n",
      "new_state[0] ==>\n",
      " LSTMStateTuple(c=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32), h=array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]], dtype=float32)) \n",
      "size ==>\n",
      " 2\n",
      "\n",
      "new_state[0][0] ==>\n",
      " [[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]] \n",
      "size ==>\n",
      " 10\n",
      "\n",
      "new_state[0][0][0] ==>\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.] \n",
      "size ==>\n",
      " 128\n",
      "\n",
      "x ==>\n",
      " [[47 64 65 80 45 46 36 73 20 72 72 72 75 65 80 80 78 73 56 65 69 81 19 81\n",
      "  46 41 73 65 36 46 73 65 19 19 73 65 19 81 55 46 58 73 46 34 46 36 78 73\n",
      "  70 14]\n",
      " [73 65 69 73 14 11 45 73 26 11 81 14 26 73 45 11 73 41 45 65 78 43 22 73\n",
      "  65 14 41 74 46 36 46 21 73 29 14 14 65 43 73 41 69 81 19 81 14 26 43 73\n",
      "   8 70]\n",
      " [34 81 14  2 72 72 22 12 46 41 43 73 81 45 42 41 73 41 46 45 45 19 46 21\n",
      "   2 73 57 64 46 73 80 36 81  7 46 73 81 41 73 69 65 26 14 81 56 81  7 46\n",
      "  14 45]\n",
      " [14 73 21 70 36 81 14 26 73 64 81 41 73  7 11 14 34 46 36 41 65 45 81 11\n",
      "  14 73 74 81 45 64 73 64 81 41 72  8 36 11 45 64 46 36 73 74 65 41 73 45\n",
      "  64 81]\n",
      " [73 81 45 73 81 41 43 73 41 81 36 68 22 73 41 65 81 21 73 45 64 46 73 11\n",
      "  19 21 73 69 65 14 43 73 26 46 45 45 81 14 26 73 70 80 43 73 65 14 21 72\n",
      "   7 36]\n",
      " [73 44 45 73 74 65 41 72 11 14 19 78 73 74 64 46 14 73 45 64 46 73 41 65\n",
      "  69 46 73 46 34 46 14 81 14 26 73 64 46 73  7 65 69 46 73 45 11 73 45 64\n",
      "  46 81]\n",
      " [64 46 14 73  7 11 69 46 73 56 11 36 73 69 46 43 22 73 41 64 46 73 41 65\n",
      "  81 21 43 73 65 14 21 73 74 46 14 45 73  8 65  7 55 73 81 14 45 11 73 45\n",
      "  64 46]\n",
      " [58 73  8 70 45 73 14 11 74 73 41 64 46 73 74 11 70 19 21 73 36 46 65 21\n",
      "  81 19 78 73 64 65 34 46 73 41 65  7 36 81 56 81  7 46 21 43 73 14 11 45\n",
      "  73 69]\n",
      " [45 73 81 41 14 42 45  2 73 57 64 46 78 42 36 46 73 80 36 11 80 36 81 46\n",
      "  45 11 36 41 73 11 56 73 65 73 41 11 36 45 43 72  8 70 45 73 74 46 42 36\n",
      "  46 73]\n",
      " [73 41 65 81 21 73 45 11 73 64 46 36 41 46 19 56 43 73 65 14 21 73  8 46\n",
      "  26 65 14 73 65 26 65 81 14 73 56 36 11 69 73 45 64 46 73  8 46 26 81 14\n",
      "  14 81]] \n",
      "x.shape ==>\n",
      " (10, 50) \n",
      "y ==>\n",
      " [[64 65 80 45 46 36 73 20 72 72 72 75 65 80 80 78 73 56 65 69 81 19 81 46\n",
      "  41 73 65 36 46 73 65 19 19 73 65 19 81 55 46 58 73 46 34 46 36 78 73 70\n",
      "  14 47]\n",
      " [65 69 73 14 11 45 73 26 11 81 14 26 73 45 11 73 41 45 65 78 43 22 73 65\n",
      "  14 41 74 46 36 46 21 73 29 14 14 65 43 73 41 69 81 19 81 14 26 43 73  8\n",
      "  70 73]\n",
      " [81 14  2 72 72 22 12 46 41 43 73 81 45 42 41 73 41 46 45 45 19 46 21  2\n",
      "  73 57 64 46 73 80 36 81  7 46 73 81 41 73 69 65 26 14 81 56 81  7 46 14\n",
      "  45 34]\n",
      " [73 21 70 36 81 14 26 73 64 81 41 73  7 11 14 34 46 36 41 65 45 81 11 14\n",
      "  73 74 81 45 64 73 64 81 41 72  8 36 11 45 64 46 36 73 74 65 41 73 45 64\n",
      "  81 14]\n",
      " [81 45 73 81 41 43 73 41 81 36 68 22 73 41 65 81 21 73 45 64 46 73 11 19\n",
      "  21 73 69 65 14 43 73 26 46 45 45 81 14 26 73 70 80 43 73 65 14 21 72  7\n",
      "  36 73]\n",
      " [44 45 73 74 65 41 72 11 14 19 78 73 74 64 46 14 73 45 64 46 73 41 65 69\n",
      "  46 73 46 34 46 14 81 14 26 73 64 46 73  7 65 69 46 73 45 11 73 45 64 46\n",
      "  81 73]\n",
      " [46 14 73  7 11 69 46 73 56 11 36 73 69 46 43 22 73 41 64 46 73 41 65 81\n",
      "  21 43 73 65 14 21 73 74 46 14 45 73  8 65  7 55 73 81 14 45 11 73 45 64\n",
      "  46 64]\n",
      " [73  8 70 45 73 14 11 74 73 41 64 46 73 74 11 70 19 21 73 36 46 65 21 81\n",
      "  19 78 73 64 65 34 46 73 41 65  7 36 81 56 81  7 46 21 43 73 14 11 45 73\n",
      "  69 58]\n",
      " [73 81 41 14 42 45  2 73 57 64 46 78 42 36 46 73 80 36 11 80 36 81 46 45\n",
      "  11 36 41 73 11 56 73 65 73 41 11 36 45 43 72  8 70 45 73 74 46 42 36 46\n",
      "  73 45]\n",
      " [41 65 81 21 73 45 11 73 64 46 36 41 46 19 56 43 73 65 14 21 73  8 46 26\n",
      "  65 14 73 65 26 65 81 14 73 56 36 11 69 73 45 64 46 73  8 46 26 81 14 14\n",
      "  81 73]] \n",
      "y.shape ==>\n",
      " (10, 50)\n",
      "\n",
      "inputs=x ==>\n",
      " Tensor(\"inputs:0\", shape=(10, 50), dtype=int32)\n",
      "\n",
      "x_one_hot ==>\n",
      " Tensor(\"one_hot:0\", shape=(10, 50, 83), dtype=float32)\n",
      "\n",
      "targets=y ==>\n",
      " Tensor(\"targets:0\", shape=(10, 50), dtype=int32)\n",
      "\n",
      "initial_state==>\n",
      " (LSTMStateTuple(c=<tf.Tensor 'zeros:0' shape=(10, 128) dtype=float32>, h=<tf.Tensor 'zeros_1:0' shape=(10, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'zeros_2:0' shape=(10, 128) dtype=float32>, h=<tf.Tensor 'zeros_3:0' shape=(10, 128) dtype=float32>))\n",
      "\n",
      "lstm==>\n",
      " <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.MultiRNNCell object at 0x1249999e8>\n",
      "\n",
      "outputs ==>\n",
      " Tensor(\"rnn/transpose:0\", shape=(10, 50, 128), dtype=float32)\n",
      "\n",
      "final_state ==>\n",
      " (LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_2:0' shape=(10, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_3:0' shape=(10, 128) dtype=float32>), LSTMStateTuple(c=<tf.Tensor 'rnn/while/Exit_4:0' shape=(10, 128) dtype=float32>, h=<tf.Tensor 'rnn/while/Exit_5:0' shape=(10, 128) dtype=float32>))\n",
      "\n",
      "prediction==>\n",
      " Tensor(\"prediction:0\", shape=(500, 83), dtype=float32)\n",
      "\n",
      "logits==>\n",
      " Tensor(\"add:0\", shape=(500, 83), dtype=float32)\n",
      "\n",
      "loss==>\n",
      " Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "\n",
      "optimizer ==>\n",
      " name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_0/basic_lstm_cell/weights/ApplyAdam\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_0/basic_lstm_cell/biases/ApplyAdam\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_1/basic_lstm_cell/weights/ApplyAdam\"\n",
      "input: \"^Adam/update_rnn/multi_rnn_cell/cell_1/basic_lstm_cell/biases/ApplyAdam\"\n",
      "input: \"^Adam/update_softmax/Variable/ApplyAdam\"\n",
      "input: \"^Adam/update_softmax/Variable_1/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "Training Step: 1...  Training loss: 4.4207...  0.1724 sec/batch\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "# Save every N iterations\n",
    "save_every_n = 200\n",
    "\n",
    "model = CharRNN(len(vocab), batch_size=batch_size, num_steps=num_steps,\n",
    "                lstm_size=lstm_size, num_layers=num_layers, \n",
    "                learning_rate=learning_rate)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=100)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Use the line below to load a checkpoint and resume training\n",
    "#     saver.restore(sess, 'checkpoints/i78200_l128.ckpt')\n",
    "    counter = 0\n",
    "    for e in range(epochs):\n",
    "        # Train network\n",
    "        new_state = sess.run(model.initial_state)\n",
    "        loss = 0\n",
    "        for x, y in get_batches(encoded, batch_size, num_steps):\n",
    "            counter += 1\n",
    "            start = time.time()\n",
    "            feed = {model.inputs: x,\n",
    "                    model.targets: y,\n",
    "                    model.keep_prob: keep_prob,\n",
    "                    model.initial_state: new_state}\n",
    "            batch_loss, new_state, _ = sess.run([model.loss, \n",
    "                                                 model.final_state, \n",
    "                                                 model.optimizer], \n",
    "                                                 feed_dict=feed)\n",
    "            \n",
    "            end = time.time()\n",
    "            print('Epoch: {}/{}... '.format(e+1, epochs),\n",
    "                  'Training Step: {}... '.format(counter),\n",
    "                  'Training loss: {:.4f}... '.format(batch_loss),\n",
    "                  '{:.4f} sec/batch'.format((end-start)))\n",
    "        \n",
    "            if (counter % save_every_n == 0):\n",
    "                saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))\n",
    "    \n",
    "    saver.save(sess, \"checkpoints/i{}_l{}.ckpt\".format(counter, lstm_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
